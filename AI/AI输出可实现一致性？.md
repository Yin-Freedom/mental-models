# AI输出可实现一致性？



## AI研究的方法论

众所周知，人类科学发展基于科学的方法

- **假说-演绎法**：提出假设，通过演绎逻辑推理得出可检验的结论。
- **逻辑推理**：依赖严密的逻辑体系来建立知识体系。
- **数学工具**：使用数学方法对自然现象进行定量描述和建模。
- **知识积累与传承**：通过文献、论文等方式沉淀和传递知识。
- **开放合作**：科学家跨学科、跨地域协作，推动集体智慧。
- **技术进步**：新仪器、新计算方法不断扩展科学研究的边界。

> 这些传统科学方法的核心，是“可解释、可预测、可复现”。

然而，近年来大模型（深度学习、生成式AI等）的飞速发展，推动了科学研究范式的转变，尤其在**人工智能、生命科学、材料科学**等领域尤为突出。

### 从理论主导到数据驱动

缺乏理论支撑导致“知其然不知其所以然”，让人难以解释和预测现象。使得科学研究从“假设-推理-验证”的研究方法，转向了“数据-训练-实验-应用”的研究方法。即使拥有同样数据、同样的条件、同样的人，也难以复刻别人的成功。目前的景象就是，科技巨头争先提高AI基础设施、算力的预算。

2025年年初，亚马逊、谷歌、微软和 Meta 等科技巨头预计将大幅增加AI基础设施和算力投入。仅这四家公司，2025财年的总资本支出预计将超2150亿美元，年增长率超45%。大公司们在大模型理论不完备、可重复性未完全解决的情况下，已对AI投入巨大。

2024年诺奖得主 Demis Hassabis 更是豪言：“到2030年，实现通用人工智能（AGI）的概率高达50%。”

但**大模型能否通过科学理论预测其能力上限？能否可重复地不断提高性能？**这仍然是悬而未决的科学难题。

## 大模型输出：概率机制本质

![LLM output](.\data\LLM output.webp)

人们使用大模型基本都是输入提示词，然后得到大模型的输出。对于大模型内部的工作机制的了解，能够让我们清楚

- 大模型核心是一张**概率分布表**，每一步的输出都是基于当前上下文与历史状态，计算下一个token的概率分布，再根据**解码策略**选择输出。
- 这种机制导致**同样输入、同样参数，输出结果也可能因细节差异而不同**。

想象一个极其擅长模仿和组合的作家，他读过互联网上几乎所有的公开文本。他写的东西听起来都很合理、流畅，但他所有的想法都源于他“读过的内容”。他不能真正“经历”现实的物理世界，只能根据过去的数据“推测”你想要什么。大模型是过去的产物，不存在于当下和未来。

### 数值精度对大模型的影响

#### 1. 论文研究结论

> G. Feng et al., "How Numerical Precision Affects Arithmetical Reasoning Capabilities of LLMs," arXiv:2410.13857 [cs.LG], 2025. [Online]. Available: https://arxiv.org/abs/2410.13857

文章系统研究了数值精度对大语言模型（Transformer架构）执行算数推理任务的影响。表明数值精度是影响LLM在算术任务中的关键因素。表现在：

- **标准数值精度（BF32）**的Transformer能够以较小的模型尺寸处理算术任务（整数加法、迭代加法、整数乘法）。
- **低数值精度（BF16, float8, int8, or even int4）**可以节省内存和计算资源，但无法处理如迭代加法、整数乘法之类的算数任务。
- **精度比对参数更关键**（推论。（1）原文Theorem 4.2/4.3证明无论模型多大，低精度都无法解决相关的数学问题。（2）提高数值精度是解决数学问题的关键）。

<div style="display: flex; justify-content: space-between;">
  <img src=".\data\Floating-point format of FP32, FP16 and BF16.png" alt="图片1" width="48%" height=“48%”>
  <img src=".\data\Model performance on different tasks in base-2_float32 and bfloat16.png" alt="图片2" width="48%" height=“48%”>
</div>

> 图片1：FP32、FP16 和 BF16 的浮点格式。
>
> 图片2：不同精度、层数的模型在数学任务上的表现对比。float32明显优于bfloat16。

#### 2. BF16在不同条件下对模型推理的影响

BF16（bfloat16）是一种常用的低精度数值格式，常用于提升大模型的推理效率和降低显存消耗，但同时也带来一系列数值稳定性和可复现性的问题。

- BF16精度本身的局限

  BF16 的有效位数只有 7 位（而 FP32 有 23 位），这意味着它能表示和区分的数值范围远小于 FP32。小数值的累积误差、舍入误差、溢出或下溢的概率显著增加。

- 并行策略（如张量并行大小）的影响

  - **张量并行（Tensor Parallelism）**会将一个大的神经网络层分布到多个设备（如多张 GPU）上，每张设备处理一部分数据，并最终聚合结果。
  - 在FP32下，数据的拆分和聚合通常不会带来明显误差。
  - 但在BF16下，**聚合顺序和方式不同**，每一步的舍入误差都会被放大，不同的张量并行大小会导致聚合路径、通信细节不一样，进而影响最终的数值结果。

- 批次大小的影响

  - **批次大小**会影响参数更新、归一化（比如 BatchNorm）、损失缩放等运算的具体数值。
  - 在 BF16 下，由于有效精度低，累加（如全批量求和、均值、方差）时的小误差会因批次大小不同而累积放大，导致推理结果出现差异。


- 硬件差异

BF16（bfloat16）极大提升了训练、推理效率，降低显存消耗，是业界主流。但BF16有效位数仅7位，累积误差、舍入误差、数值不稳定性更高。尤其在大规模并行、批量归一化等场景下，不同的张量分割、聚合顺序会放大误差，影响最终输出。

### 解码策略对一致性与多样性的影响

在大语言模型（LLM）文本生成过程中，解码策略（Decoding Strategy）决定了如何从模型输出的下一个 token 概率分布中选择实际输出。解码策略的不同，直接影响生成文本的**一致性（Consistency）**与**多样性（Diversity）**，并已成为自然语言生成领域的重要研究问题。

如下是目前常用的一些解码策略：

| 方法                                                         | 说明                                                         | 多样性 | 质量  | 速度 | 控制参数  | 特点                 |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------ | ----- | ---- | --------- | -------------------- |
| 贪婪解码（Greedy Decoding）                                  | 每一步都选择概率最高的下一个token                            | 低     | 低    | 快   | 无        | 结果单一             |
| 集束搜索（Beam Search）                                      | 同时保留概率最高的k个序列（称为beam width），每一步扩展这k个序列，然后再选择k个最优的继续扩展。<br />例如，一个k为2的搜索，每次保留2个序列。![beam search example with b = 2](.\data\beam search example with b = 2.webp) | 低-中  | 中    | 慢   | beam size | 结果较好，易重复     |
| 随机采样（Sampling）<br />1. 标准采样（Random Sampling）<br />2. Top-k采样（Top-k Sampling）<br />3. Top-p采样（Nucleus Sampling） | 1. 每一步按概率分布随机采样下一个token<br />2. 仅从概率最高的前k个token中采样，去除概率很低的token<br />3. 从累计概率前p的token集合中采样，而不是固定个数 | 中-高  | 中-高 | 快   |           | 兼顾多样性和质量     |
| 温度调节（Temperature Scaling）                              | 温度参数T控制概率分布的“平滑度”：T<1更偏向高概率token，T>1增加多样性。常与采样方法结合使用。 | 高     | 中    | 快   | T         | 与采样结合调节多样性 |
| 重复惩罚（Repetition Penalty）                               | 在采样时对已经生成过的token降低其概率，减少模型生成重复内容的倾向。 | -      | 高    | -    | penalty   | 避免重复             |
| 组合方法                                                     | 如“Top-p采样+温度调节+重复惩罚”，以获得更理想的生成效果。    |        |       |      |           |                      |



### 可重复性实验与数值精度挑战

浮点运算本身的非结合性、有限精度和舍入误差，加上AI模型的概率解码机制，导致即使微小的数值波动（如批次大小、并行策略、硬件差异）也能引起输出差异。LLM的输出往往是概率最接近的几个token之间竞争，微小扰动即可改变最终选择。

![changes in evaluation batch size alone can lead to noticeable differences in responses](.\data\changes in evaluation batch size alone can lead to noticeable differences in responses.png)

> 图：仅评估批次大小的变化即可带来明显的输出差异

现实情况下，许多研究人员的报告不具有可重复性，基于随机抽样的基准测试，难以区分一次超常的表现是来自于方法的改进还是随机变化。

论文提出了一种可重复的解决方案。该论文分析了数值精度和硬件配置对LLM可重复性的影响。结果表明，使用常用的 BF16 精度进行推理对硬件和系统配置的变化高度敏感，例如张量并行大小、评估批次大小和 GPU 类型。

> Yuan, Jiayi, et al. "Give Me FP32 or Give Me Death? Challenges and Solutions for Reproducible Reasoning." *arXiv preprint arXiv:2506.09501* (2025). Available: https://arxiv.org/html/2506.09501v1

另外，该文章表明

- 贪婪解码： FP32 始终保持近乎完美的可重复性，FP16 表现出中等程度的差异，BF16 表现出明显的不稳定性。

  影响：不同类型的GPU、不同GPU数量、响应长度，都可能影响复现他人的结果。

- 随机采样：数值精度也会显著影响基于采样的评估的稳定性和可重复性

因此，该文章提出了一个解决方案：训练时使用 BF16 训练以减小内存消耗和加快训练，在推理时使用混合精度（FP32 + BF16）处理计算。



### DeepSeek-R1的实践

> DeepSeek-AI et al., "DeepSeek LLM: Scaling Open-Source Language Models with Longtermism" arXiv:2401.02954 [cs.LG], 2024. [Online]. Available: https://arxiv.org/abs/2401.02954

DeepSeek-R1 是由 DeepSeek 团队发布的大规模开源语言模型，一经推出便引起了全球大模型界的广泛关注。

其采用 BF16 进行训练和推理，带来了更高的训练效率、更低的显存和带宽占用，以及几乎不损失精度的数值稳定性。BF16 是当前大模型训练的主流数值格式，兼顾了速度、成本与性能。那么 BF16 数值精度的影响是什么？

- 无影响：常规NLP任务（自然语言处理，如对话、理解、生成）：对数值精度不敏感，BF16可安全使用，兼顾性能与精度。
- 有影响：科学计算（如科学建模、物理仿真、分子动力学、气象模拟等），金融分析（金融风险评估、量化交易），医学（医学图像重建、放射治疗计划等需要高精度的医疗场景）。

解决有影响情况的办法：在推理时保留FP32，或至少在关键计算模块用FP32，避免全流程BF16，确保数值不失真。



## 为什么大语言模型如此强大

可能有几方面。

首先，缩放定律（Scaling Laws）和 Transformer 的发明共同奠定了大模型发展的技术基石，使得大模型能够处理海量的数据。

> Kaplan, Jared, et al. "Scaling laws for neural language models." *arXiv preprint arXiv:2001.08361* (2020).
>
> Vaswani, Ashish, et al. "Attention is all you need." *Advances in neural information processing systems* 30 (2017).

![An encoder-decoder network trained to output the same word as the input (it’s the same image as before but with color for activation)](.\data\An encoder-decoder network trained to output the same word as the input (it’s the same image as before but with color for activation).gif)

> 图：经过训练的编码器-解码器网络输出与输入相同的单词

其次，互联网时代的去中心化数据为大模型训练提供了前所未有的原材料。互联网数据的分布式、无中心化特点，意味着没有哪个国家或机构能独自囊括全部人类知识。数据的多样性和开放性，使大模型能够接触、学习、整合多元文化、语言、专业领域的信息。训练大语言模型所需的数据量已达万亿级别，这些文本数据涵盖了人类表达、知识体系、语境、逻辑与常识等各个层面。与传统数据库或知识图谱相比，大语言模型的目标不是简单检索事实，而是**在给定上下文中生成下一个文本**，实现了更高阶的语言理解和生成能力。

然而，模型本身也承载着人类认知与历史的局限性。 Heraclitus 曾说：“人不能两次踏进同一条河流“。现实中人类常常重复同样的失败——固定的思维模式、集体记忆的缺失让历史不断“押韵”，甚至重演。因为人类思维的固定行为模式、思维惯性、集体记忆的缺失，大模型的本质同样如此。尽管每次输入看似全新，模型实际是对庞大语料中的“相似片段”进行参数化记忆和概率化抽象。它的输出是过去无数语言片段的“碎片化拼接”，本质上仍然是历史经验的重组。不过，这种基于概率分布的生成远超传统的数据检索或模板方法。大模型不仅能模仿，更能泛化，在极大程度上突破了机械式复现，展现出类人智能的某些特质。



## AI革命的未来

其实，很多人都想知道，AI是否是一场真正的科技革命，能否带来一场如同互联网般的全球性变革？

老实说，我也不知道。OpenAI的Sam Altman，Nvidia的黄仁勋，微软的比尔·盖茨，谷歌 DeepMind 的 Demis Hassabis（2024年诺贝尔奖得主）等，这些业界领袖都坚信，在不久的未来，甚至可能在2030年之前，AI的发展将迎来重大突破，而人类社会也可能因此发生翻天覆地的变化。这种变化不仅仅体现在生产率的提高，更有可能重塑世界经济体系、全球政治格局，以及医学、教育、能源等所有学科和产业。

回顾历史，每一次“科技革命“不仅是技术的积累和突破，也是人类社会内部的经济、政治、社会等出现了不可调和的矛盾，毕竟，不向前就只能倒退，没有止步可言。

正如互联网、移动通信、基因工程等颠覆性技术，AI的发展路径并非直线。它可能经历泡沫、低谷和再度崛起。每一次技术浪潮初期都伴随着巨大的希望与夸张的宣传，但最终只有真正解决现实问题、创造新价值的技术，才能被历史铭记。或许，AI革命的“临界点”还需时日，但毫无疑问，我们正身处一个技术加速的新时代。AI的每一次突破，都是人类知识、技术和社会的共同进步。未来几年，无论是拥抱变革、主动参与，还是理性审视、谨慎前行，都是我们每个人和整个人类社会必须面对的重要命题。

“历史不会简单重复，但会押韵。”我们无法预知未来AI会引发怎样的革命，但我们正共同见证着一个伟大时代的到来。



## 参考

- [Understanding LLM Decoding Strategies](https://medium.com/@lmpo/mastering-llms-a-guide-to-decoding-algorithms-c90a48fd167b)

- [WSJ_2025-02-06_Tech Giants Double Down on Their Massive AI Spending](https://www.wsj.com/tech/ai/tech-giants-double-down-on-their-massive-ai-spending-b3040b33)

- [Youtube_2025-07-24_Demis Hassabis](https://lexfridman.com/demis-hassabis-2-transcript)

- [A Very Gentle Introduction to Large Language Models without the Hype](https://mark-riedl.medium.com/a-very-gentle-introduction-to-large-language-models-without-the-hype-5f67941fa59e)

- 其余引用详见正文与原论文。
